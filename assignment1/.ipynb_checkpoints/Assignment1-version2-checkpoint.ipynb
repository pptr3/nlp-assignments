{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnHoYqQS5eV1"
   },
   "source": [
    "# Intro\n",
    "In this assignement you will see a little example about\n",
    "*   How to download a dataset\n",
    "*   How to load it into dataframes\n",
    "*   How to use extract basic features from the corpus\n",
    "*   How to train a classifier on those features\n",
    "\n",
    "You are advised to look at the code and understand it.\n",
    "\n",
    "You will be then asked to perform feature extraction and classification yourself.\n",
    "\n",
    "The task that will be addressed is document classification, specifically tasks related to sentiment classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARCKuf1S5GKg"
   },
   "source": [
    "# Document Classification Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8aVUWrD3LeW"
   },
   "source": [
    "## Preliminary Steps\n",
    "These are some preliminary steps before addressing the task.\n",
    "Import some basic libraries and set a variable that will be used in multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of3D92OeWV8_"
   },
   "outputs": [],
   "source": [
    "# The libraries we will use are imported here, in case of runtime problems\n",
    "import os, shutil  #  file management\n",
    "import sys\n",
    "import pandas as pd  #  dataframe management\n",
    "import numpy as np  #  data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgXmCToDOAbQ"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCjPTD4a6uTb"
   },
   "source": [
    "CHANGED: If it is necessary, clean all the data that are in the DATASETS directory and wipe out all the subdirectories.\n",
    "\n",
    "IMPORTANT: DO NOT RUN THIS SECTION UNLESS YOU NEED IT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "iSbT57Bo6wkV",
    "outputId": "f5093bf5-cc61-4b0d-e8c4-59f92bc690d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: /content\n",
      "Cleaned\n"
     ]
    }
   ],
   "source": [
    "folder = os.getcwd()\n",
    "\n",
    "print(\"Current work directory: \" + str(folder))\n",
    "\n",
    "dataset_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "\n",
    "for filename in os.listdir(dataset_folder):\n",
    "    file_path = os.path.join(dataset_folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "print(\"Cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d--rS8W95i62"
   },
   "source": [
    "## Dataset Download\n",
    "Dowload the Imdb movie reviews dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "aLNJIfZg4_d9",
    "outputId": "1c820649-b716-4b07-9b76-ed0407bfda14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful download\n",
      "Successful extraction\n"
     ]
    }
   ],
   "source": [
    "import urllib.request  #  download files\n",
    "import tarfile  #  unzip files\n",
    "\n",
    "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "\n",
    "url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "dataset_path = os.path.join(dataset_folder, \"Movies.tar.gz\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"Successful download\")\n",
    "\n",
    "tar = tarfile.open(dataset_path)\n",
    "tar.extractall(dataset_folder)\n",
    "tar.close()\n",
    "print(\"Successful extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3f93BOW3ziB"
   },
   "source": [
    "Look at the files you have downloaded to understand the structure of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FexYdgu87Q3"
   },
   "source": [
    "## Create the dataframe\n",
    "Now the dataset is loaded into a dataframe to be more accessible.\n",
    "During the creation some data will be printed as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "4u8aN92x9Aw1",
    "outputId": "ddcc9778-9cd3-4d6d-8e0f-401c365835a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Datasets/Original/aclImdb/train/pos/8460_7.txt\n",
      "8460_7.txt\n",
      "8460\n",
      "Gundam Wing is a fun show. I appreciate it for getting me into Gundam and anime in general. However, after watching its predecessors, such as Mobile Suit Gundam, Zeta Gundam, and even G Gundam, I find Wing to be Gundam Lite.<br /><br />Characters: An aspect long held by Gundam is to have their characters thrust into difficulties and grow into maturity. This does not happen in Wing. Heero is top dog at the beginning, and he's top dog at the end. Personalities do not change, growth is never achieved. The best character is Zechs, who is for all intents and purposes a hero throughout most of the series. But suddenly the series betrays him and turns him into a villain for no apparent reason.<br /><br />Mecha: Wing has great suit designs. The Gundams are super cool, with the Epyon being my favorite. I even consider a few of the OZ suit designs to be on par with some of the classic Zeon suits. But sweet suit designs doesn't quite save the series from boring characters.<br /><br />Conclusion: In the end, Wing has cool fight scenes, though riddled with recycled animation, but shallow plot and character development. Enjoyable, but not moving like previous Gundam outings.\n",
      "7\n",
      "pos\n",
      "train\n",
      "{'file_id': '8460', 'score': '7', 'sentiment': 1, 'split': 'train', 'text': \"Gundam Wing is a fun show. I appreciate it for getting me into Gundam and anime in general. However, after watching its predecessors, such as Mobile Suit Gundam, Zeta Gundam, and even G Gundam, I find Wing to be Gundam Lite.<br /><br />Characters: An aspect long held by Gundam is to have their characters thrust into difficulties and grow into maturity. This does not happen in Wing. Heero is top dog at the beginning, and he's top dog at the end. Personalities do not change, growth is never achieved. The best character is Zechs, who is for all intents and purposes a hero throughout most of the series. But suddenly the series betrays him and turns him into a villain for no apparent reason.<br /><br />Mecha: Wing has great suit designs. The Gundams are super cool, with the Epyon being my favorite. I even consider a few of the OZ suit designs to be on par with some of the classic Zeon suits. But sweet suit designs doesn't quite save the series from boring characters.<br /><br />Conclusion: In the end, Wing has cool fight scenes, though riddled with recycled animation, but shallow plot and character development. Enjoyable, but not moving like previous Gundam outings.\"}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"aclImdb\"\n",
    "\n",
    "debug = True\n",
    "\n",
    "dataframe_rows = []\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\", dataset_name, split, sentiment)\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    # open the file\n",
    "                    with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
    "                        # read it and extract informations\n",
    "                        text = text_file.read()\n",
    "                        score = filename.split(\"_\")[1].split(\".\")[0]\n",
    "                        file_id = filename.split(\"_\")[0]\n",
    "\n",
    "                        num_sentiment = -1\n",
    "\n",
    "                        if sentiment == \"pos\" : num_sentiment = 1\n",
    "                        elif sentiment == \"neg\" : num_sentiment = 0\n",
    "\n",
    "                        # create single dataframe row\n",
    "                        dataframe_row = {\n",
    "                            \"file_id\": file_id,\n",
    "                            \"score\": score,\n",
    "                            \"sentiment\": num_sentiment,\n",
    "                            \"split\": split,\n",
    "                            \"text\": text\n",
    "                        }\n",
    "\n",
    "                        # print detailed info for the first file\n",
    "                        if debug:\n",
    "                            print(file_path)\n",
    "                            print(filename)\n",
    "                            print(file_id)\n",
    "                            print(text)\n",
    "                            print(score)\n",
    "                            print(sentiment)\n",
    "                            print(split)\n",
    "                            print(dataframe_row)\n",
    "                            debug = False\n",
    "                        dataframe_rows.append(dataframe_row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Failed to process %s. Reason: %s' % (file_path, e))\n",
    "                sys.exit(0)\n",
    "\n",
    "folder = os.path.join(os.getcwd(), \"Datasets\", \"Dataframes\", dataset_name)\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# transform the list of rows in a proper dataframe\n",
    "dataframe = pd.DataFrame(dataframe_rows)\n",
    "dataframe = dataframe[[\"file_id\",\n",
    "                       \"score\",\n",
    "                       \"sentiment\",\n",
    "                       \"split\",\n",
    "                       \"text\"]]\n",
    "dataframe_path = os.path.join(folder, dataset_name + \".pkl\")\n",
    "dataframe.to_pickle(dataframe_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH_BAvFKF76g"
   },
   "source": [
    "Little analysis of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "id": "GCs9IEO5F-Vt",
    "outputId": "a3a5252c-0d67-4d21-b925-ead27d50a820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe structure:\n",
      "      file_id score  ...  split                                               text\n",
      "0        8460     7  ...  train  Gundam Wing is a fun show. I appreciate it for...\n",
      "1        6065    10  ...  train  This movie is horrible- in a 'so bad it's good...\n",
      "2        7905    10  ...  train  I feel very sorry for people who go to movies ...\n",
      "3        2836     7  ...  train  Recap: Zandalee is a young woman that feels mo...\n",
      "4       10468     9  ...  train  Monstervision was a show I grew up with. From ...\n",
      "...       ...   ...  ...    ...                                                ...\n",
      "49995    2839     1  ...   test  This movie was the slowest and most boring so ...\n",
      "49996    3250     1  ...   test  This movie beats everything out there. Well, d...\n",
      "49997   12007     2  ...   test  I am having a hard time finding the words to e...\n",
      "49998    9169     1  ...   test  Steve Smith has finally run a fairly weak seri...\n",
      "49999    8988     1  ...   test  I watched this movie for the hot guy--and even...\n",
      "\n",
      "[50000 rows x 5 columns]\n",
      "\n",
      "Total rows 50000\n",
      "\n",
      "Distribution of scores: \n",
      "1     10122\n",
      "10     9731\n",
      "8      5859\n",
      "4      5331\n",
      "3      4961\n",
      "7      4803\n",
      "9      4607\n",
      "2      4586\n",
      "Name: score, dtype: int64\n",
      "\n",
      "Distribution of sentiment: \n",
      "1    25000\n",
      "0    25000\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Distribution of scores in train: \n",
      "1     5100\n",
      "10    4732\n",
      "8     3009\n",
      "4     2696\n",
      "7     2496\n",
      "3     2420\n",
      "2     2284\n",
      "9     2263\n",
      "Name: score, dtype: int64\n",
      "\n",
      "Distribution of scores in test: \n",
      "1     5022\n",
      "10    4999\n",
      "8     2850\n",
      "4     2635\n",
      "3     2541\n",
      "9     2344\n",
      "7     2307\n",
      "2     2302\n",
      "Name: score, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_path = os.path.join(os.getcwd(), \"Datasets\", \"Dataframes\", dataset_name, dataset_name + \".pkl\")\n",
    "df = pd.read_pickle(dataframe_path)\n",
    "\n",
    "print(\"Dataframe structure:\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Total rows %d\" % (len(df)))\n",
    "print()\n",
    "\n",
    "column = 'score'\n",
    "print(\"Distribution of scores: \")\n",
    "print(df[column].value_counts())\n",
    "print()\n",
    "\n",
    "column = 'sentiment'\n",
    "print(\"Distribution of sentiment: \")\n",
    "print(df[column].value_counts())\n",
    "print()\n",
    "\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    df1 = df.loc[df['split'] == split]\n",
    "    column = 'score'\n",
    "    print(\"Distribution of scores in %s: \" % (split))\n",
    "    print(df1[column].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzoExTTDxqwz"
   },
   "source": [
    "A little game: let's create a word cloud for the two sentiments and see if there is something interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6FNPW5lx4R5"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataframe_path = os.path.join(os.getcwd(), \"Datasets\", \"Dataframes\", dataset_name, dataset_name + \".pkl\")\n",
    "df = pd.read_pickle(dataframe_path)\n",
    "\n",
    "positive_corpus = df.loc[df['sentiment'] == 1]\n",
    "positive_corpus = positive_corpus[\"text\"].tolist()\n",
    "\n",
    "negative_corpus = df.loc[df['sentiment'] == 0]\n",
    "negative_corpus = negative_corpus[\"text\"].tolist()\n",
    "\n",
    "print(\"Negative:\")\n",
    "wordcloud1 = WordCloud(width = 3000, height = 2000, collocations=False, stopwords = STOPWORDS).generate(\" \".join(negative_corpus))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud1) \n",
    "plt.axis(\"off\");\n",
    "plt.show()\n",
    "\n",
    "print(\"Positive:\")\n",
    "wordcloud2 = WordCloud(width = 3000, height = 2000, collocations=False, stopwords = STOPWORDS).generate(\" \".join(positive_corpus))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud2) \n",
    "plt.axis(\"off\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFhnc_g4y00b"
   },
   "source": [
    "Is there something weird about these words? You can repeat the process multiple times to test your observations.\n",
    "Is there something that will influence our approach? Think about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APy7Yb83H5Is"
   },
   "source": [
    "## Features extraction\n",
    "Let's tackle the Sentiment Analysis task.\n",
    "\n",
    "The scikit-learn library offers *TfidfVectorizer*, a class that performs both tokenization and the creation of the BoW representation (as tf-idf) of a corpus.\n",
    "\n",
    "The class has plenty of options: it can be used also to count n-grams, excluding stop-words, and cutting off most and/or less frequent terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsuUwTjqH72Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "dataframe_path = os.path.join(os.getcwd(), \"Datasets\", \"Dataframes\", dataset_name, dataset_name + \".pkl\")\n",
    "df = pd.read_pickle(dataframe_path)\n",
    "\n",
    "# select only the training sentences\n",
    "df_train = df.loc[df['split'] == \"train\"]\n",
    "\n",
    "train_corpus = df_train['text'].tolist()\n",
    "\n",
    "print(\"Processing corpus\\n\")\n",
    "vectorizer =  TfidfVectorizer()\n",
    "# tokenization and creation of Bag of Words representation\n",
    "X_train = vectorizer.fit_transform(train_corpus)\n",
    "\n",
    "print(\"Shape of the matrix: (data points, features)\")\n",
    "print(X_train.shape)\n",
    "print()\n",
    "\n",
    "# targets for the training set\n",
    "Y_train = np.array(df_train['sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PajnwZslUg-p"
   },
   "source": [
    "Fitting on a corpus, the vectorizer creates an internal vocabulary that will be used to create the BoW representation.\n",
    "The vocabulary is a dictionary that associates to each word a corresponding column in the feature matrix.\n",
    "\n",
    "Do not try to print the whole vocabulary: it is quite large ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fMTG5wqUfhL"
   },
   "outputs": [],
   "source": [
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2KIWtBzMYef"
   },
   "source": [
    "Since the vocabulary will be quite big, by default X will be a *sparse* matrix (see scipy.sparse for more info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfcEWJaeNLWc"
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr38ssKTNMeQ"
   },
   "source": [
    "All the scipy tools are compatible with sparse matrices, but if you somehow need the traditional representation it is possible to convert it with the following command. Keep in mind that if the vocabulary and/or the dataset are large, the resulting array will be quite large, possibly occupying all the RAM.\n",
    "\n",
    "\n",
    "```\n",
    "X.toarray()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evLd40iCWZ8q"
   },
   "source": [
    "It is then possible to parse the test split likewise. Remember to use the transform function and not the fit_transform when working on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNz23Ep2Y3iB"
   },
   "outputs": [],
   "source": [
    "# select only the test sentences\n",
    "df_test = df.loc[df['split'] == \"test\"]\n",
    "test_corpus = df_test['text'].tolist()\n",
    "X_test = vectorizer.transform(test_corpus)\n",
    "Y_test = np.array(df_test['sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe5NPH5Gb5FI"
   },
   "source": [
    "## Training and Testing\n",
    "It is now possible to choose one of the many models available in the sci-kit learn library, train it and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTnd0-X2b3ke"
   },
   "outputs": [],
   "source": [
    "# training and testing\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC()\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_train = classifier.predict(X_train)\n",
    "Y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vG4oUWA0k3yS"
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_train = classification_report(Y_train, Y_pred_train, target_names=[\"neg\", \"pos\"])\n",
    "report_test = classification_report(Y_test, Y_pred_test, target_names=[\"neg\", \"pos\"])\n",
    "print(\"Train\")\n",
    "print(report_train)\n",
    "print(\"Test\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgtGYwjncFpn"
   },
   "outputs": [],
   "source": [
    "# more advanced tools\n",
    "# plot precision/recall curve and confusion matrix\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(classifier, X_test, Y_test)\n",
    "plot_confusion_matrix(classifier, X_test, Y_test, normalize='true', cmap=plt.cm.Blues, values_format=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlY-i4Yug6Dx"
   },
   "source": [
    "# Now...do it yourself!\n",
    "\n",
    "Now, rather then sentiment classification, try to address the task of score prediction on the same dataset: based on the text of the reviews, try to predict the score assigned by the reviewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMaK5y9OiTj4"
   },
   "source": [
    "## First part\n",
    "As first part, experiment with the options of the vectorizer to improve the classification using logistic regression. You are required to look at the documentation of the functions.\n",
    "You can also use or add other pre-processing steps to the text if you feel like it, you are not obliged to use TfidfVectorizer.\n",
    "\n",
    "Obviously, you will need to use the variable names declared in the first block, so to make our evaluation blocks work.\n",
    "\n",
    "\n",
    "Some notes:\n",
    "* Between the problem as regression and the problem as multi-class classification, the priority is the problem as regression. Indeed, the classification perspective does penalize each error in the same way, while the regression perspective considers the difference between the predicted value and the real value (prediction 8 for real value 2 is way worse than prediction 3 for value 2). The classification perspective is a tool to understand the problem better and experiment.\n",
    "* In the multi-class classification, the most important measures are F1s (especially macro and micro), since it is a complex measure that considers more aspects than the simple accuracy. \n",
    "* It is not unusual to not reach a \"satisfying\" score, especially in the first step: our code makes use of a pretty simple classifier. Our purpose is to show you both the impact of the pre-processing and the choice of the classifier.\n",
    "* There are no threshold values that you have to reach with the measurements to obtain a certain score. The score will be assigned based on the correctness of the methodology and the extent to which different solutions have been explored and discussed.\n",
    "* In each code section, you have to deliver a single approach, but if you have observations or interesting alternative approaches, you can mention them in the .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtraxB8Chf9X"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "X_train = None\n",
    "Y_train = None\n",
    "X_test = None\n",
    "Y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_WXt_P6MFN"
   },
   "source": [
    "Now run the code below to train your classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIN03hrxizjj"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### DO NOT MODIFY THIS PART #####################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_test = classifier.predict(X_test)\n",
    "Y_pred_test_class = np.around(Y_pred_test)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WgN0DZ0ofDf"
   },
   "source": [
    "Now test your results running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_S4aZW4k08D"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### DO NOT MODIFY THIS PART #####################\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# task as regression\n",
    "\n",
    "print(\"R2 score %f\" % (r2_score(Y_test, Y_pred_test)))\n",
    "print(\"MAE %f\" % (mean_absolute_error(Y_test, Y_pred_test)))\n",
    "print(\"MSE %f\" % (mean_squared_error(Y_test, Y_pred_test)))\n",
    "print()\n",
    "\n",
    "# task as multiclass classification\n",
    "\n",
    "report = classification_report(Y_test.astype('int'), Y_pred_test_class.astype('int'), labels=[1,2,3,4,7,8,9,10])\n",
    "print(report)\n",
    "\n",
    "confusion_matrix = confusion_matrix(Y_test.astype('int'), Y_pred_test_class.astype('int'), labels=[1,2,3,4,7,8,9,10])\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "# fancy confusion matrix\n",
    "plot_confusion_matrix(classifier, X_test, Y_test, normalize='true', cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKKVP4aPoogk"
   },
   "source": [
    "## Second part\n",
    "Now experiment both with the processing (the vectorizer) and the classifier to obtain the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXhwZl4Qoyi5"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "X_train = None\n",
    "Y_train = None\n",
    "X_test = None\n",
    "Y_test = None\n",
    "classifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6I29DPl6dRr"
   },
   "source": [
    "Run the code below to train your classifier, then test it with the block that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCebPdgYhlCf"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### DO NOT MODIFY THIS PART #####################\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_train = classifier.predict(X_train)\n",
    "Y_pred_test = classifier.predict(X_test)\n",
    "Y_pred_test_class = np.around(Y_pred_test)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE8mniZso92A"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###################### DO NOT MODIFY THIS PART #####################\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# task as regression\n",
    "\n",
    "print(\"R2 score %f\" % (r2_score(Y_test, Y_pred_test)))\n",
    "print(\"MAE %f\" % (mean_absolute_error(Y_test, Y_pred_test)))\n",
    "print(\"MSE %f\" % (mean_squared_error(Y_test, Y_pred_test)))\n",
    "print()\n",
    "\n",
    "# task as multiclass classification\n",
    "\n",
    "report = classification_report(Y_test.astype('int'), Y_pred_test_class.astype('int'), labels=[1,2,3,4,7,8,9,10])\n",
    "print(report)\n",
    "\n",
    "confusion_matrix = confusion_matrix(Y_test.astype('int'), Y_pred_test_class.astype('int'), labels=[1,2,3,4,7,8,9,10])\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "\n",
    "# fancy confusion matrix\n",
    "plot_confusion_matrix(classifier, X_test, Y_test, normalize='true', cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrTg8j0UzTWD"
   },
   "source": [
    "Credits:\n",
    "Andrea Galassi,\n",
    "Federico Ruggeri,\n",
    "Paolo Torroni\n",
    "(Oct 2020)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
