{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4_wqPdlBcKS"
   },
   "source": [
    "# Assignment 3 : Sequence labelling with RNNs\n",
    "In this assignement we will ask you to perform POS tagging.\n",
    "\n",
    "You are asked to follow these steps:\n",
    "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
    "*   Embed the words using GloVe embeddings\n",
    "*   Create a baseline model, using a simple neural architecture\n",
    "*   Experiment doing small modifications to the model\n",
    "*   Evaluate your best model\n",
    "*   Analyze the errors of your model\n",
    "\n",
    "**Corpora**:\n",
    "Ignore the numeric value in the third column, use only the words/symbols and its label.\n",
    "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip \n",
    "\n",
    "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
    "\n",
    "**Baseline**: two layers architecture: a Bidirectional LSTM and a Dense/Fully-Connected layer on top.\n",
    "\n",
    "**Modifications**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and using a CRF in addition to the LSTM. Each of this change must be done by itself (don't mix these modifications).\n",
    "\n",
    "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
    "\n",
    "**Evaluation**: in the end, only the best model of your choice must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech (without considering punctuation classes).\n",
    "\n",
    "**Error Analysis** (optional) : analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
    "\n",
    "**Report**: You are asked to deliver a small report of about 4-5 lines in the .txt file that sums up your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%autosave 1\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "base_dir = 'dependency_treebank/'\n",
    "for filename in os.listdir(base_dir):\n",
    "    with open(base_dir + filename) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [re.sub('\\s+', ' ', x) for x in content]\n",
    "\n",
    "    # remove empty strings\n",
    "    content = [x for x in content if x]\n",
    "    data.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_labels(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for document in data:\n",
    "        X_i = []\n",
    "        y_i = []\n",
    "        for i in document:\n",
    "            X_i.append(i.split(' ')[0])\n",
    "            y_i.append(i.split(' ')[1])\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_features_labels(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X)\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(y)\n",
    "y_encoded = tag_tokenizer.texts_to_sequences(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['First', 'Chicago', 'Corp.', 'said', 'it', 'completed', 'its', '$', '55.1', 'million', 'cash-and-stock', 'acquisition', 'of', 'closely', 'held', 'Ravenswood', 'Financial', 'Corp.', ',', 'another', 'Chicago', 'bank', 'holding', 'company', '.'] \n",
      "\n",
      "Y:  ['NNP', 'NNP', 'NNP', 'VBD', 'PRP', 'VBD', 'PRP$', '$', 'CD', 'CD', 'JJ', 'NN', 'IN', 'RB', 'VBN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NN', 'VBG', 'NN', '.'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [102, 156, 94, 15, 16, 1003, 36, 17, 3539, 35, 3540, 1004, 5, 1005, 403, 3541, 192, 94, 2, 196, 156, 146, 522, 42, 3] \n",
      "\n",
      "Y:  [3, 3, 3, 10, 17, 10, 22, 25, 9, 9, 6, 1, 2, 12, 16, 3, 3, 3, 7, 4, 3, 1, 18, 1, 8] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', y_encoded[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 4534\n"
     ]
    }
   ],
   "source": [
    "# check length of longest sentence\n",
    "lengths = [len(seq) for seq in X_encoded]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 2300  # sequences greater than 2300 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "y_padded = pad_sequences(y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ... 522  42   3] \n",
      "\n",
      "\n",
      "\n",
      "[ 0  0  0 ... 18  1  8]\n"
     ]
    }
   ],
   "source": [
    "print(X_padded[0], \"\\n\"*3)\n",
    "print(y_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_padded, y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2300), (100, 2300))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(model_type, embedding_dimension=50):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained word embedding model via gensim library.\n",
    "\n",
    "    :param model_type: name of the word embedding model to load.\n",
    "    :param embedding_dimension: size of the embedding space to consider\n",
    "\n",
    "    :return\n",
    "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
    "    \"\"\"\n",
    "\n",
    "    download_path = \"\"\n",
    "    '''\n",
    "    # Find the correct embedding model name\n",
    "    if model_type.strip().lower() == 'word2vec':\n",
    "        download_path = \"word2vec-google-news-300\"\n",
    "    '''\n",
    "    if model_type.strip().lower() == 'glove':\n",
    "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "\n",
    "    else:\n",
    "        raise AttributeError(\"Unsupported embedding model type! Available ones: word2vec, glove\")\n",
    "\n",
    "    # Check download\n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Word2Vec: 300\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_type = \"glove\"\n",
    "embedding_dimension = 50\n",
    "embedding_model = load_embedding_model(embedding_model_type, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523603677749634),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473883032798767),\n",
       " ('elizabeth', 0.7460220456123352),\n",
       " ('princess', 0.7424569725990295),\n",
       " ('kingdom', 0.7337411642074585),\n",
       " ('monarch', 0.7214490175247192),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099430561065674)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar(positive = [\"king\", \"woman\"], negative = [\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(df):\n",
    "    X, y = split_features_labels(df)\n",
    "    flat_list = [item for sublist in X for item in sublist]\n",
    "    vocab = set(flat_list)\n",
    "    vocab_dict = {} # word to index\n",
    "    current_index = 0\n",
    "    for v in vocab:\n",
    "        vocab_dict[v] = current_index\n",
    "        current_index += 1\n",
    "    \n",
    "    voc_index_to_word = {v: k for k, v in vocab_dict.items()}\n",
    "    \n",
    "    return voc_index_to_word, vocab_dict, np.array(list(vocab_dict.keys()))\n",
    " \n",
    "\n",
    "\n",
    "# Testing\n",
    "idx_to_word, word_to_idx, word_listing = build_vocabulary(data[:100]) # only training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_OOV_terms(embedding_model, word_listing):\n",
    "    \"\"\"\n",
    "    Checks differences between pre-trained embedding model vocabulary\n",
    "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
    "\n",
    "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
    "    :param word_listing: dataset specific vocabulary (list)\n",
    "\n",
    "    :return\n",
    "        - list of OOV terms\n",
    "    \"\"\"\n",
    "    \n",
    "    model_vocab_array = np.array(list(embedding_model.vocab.keys()))\n",
    "    return list(np.setdiff1d(word_listing, model_vocab_array))\n",
    "\n",
    "oov_terms = check_OOV_terms(embedding_model, word_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV terms: 2258 (0.28%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total OOV terms: {0} ({1:.2f}%)\".format(len(oov_terms), float(len(oov_terms)) / len(word_listing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (8068, 50)\n"
     ]
    }
   ],
   "source": [
    "def build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, oov_terms, consider_oov=True):\n",
    "    \"\"\"\n",
    "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
    "\n",
    "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
    "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
    "    :param oov_terms: list of OOV terms (list)\n",
    "    :param co_occorruence_count_matrix: the co-occurrence count matrix of the given dataset (window size 1)\n",
    "\n",
    "    :return\n",
    "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
    "    \"\"\"\n",
    "    words = np.array(list(word_to_idx.keys()))\n",
    "    embedding_matrix = np.zeros((len(words), embedding_dimension))    \n",
    "    for idx, w in enumerate(words):\n",
    "        if w not in oov_terms:\n",
    "            embedding_matrix[idx, :] = np.array(embedding_model.wv[w])\n",
    "        elif consider_oov == True and idx < len(words) and idx > 0:\n",
    "                # get the first 2 word in the vocab close to the current word index\n",
    "                below_idx = -1\n",
    "                up_idx = -1\n",
    "                model_vocab = list(embedding_model.vocab.keys())\n",
    "\n",
    "                for i in range(idx + 1, len(words)):\n",
    "                    if idx_to_word[i] in model_vocab:\n",
    "                        below_idx = i\n",
    "                        up_idx = i\n",
    "                        break\n",
    "\n",
    "                for k in reversed(range(0, idx - 1)):\n",
    "                    if idx_to_word[k] in model_vocab:\n",
    "                        up_idx = k\n",
    "                        below_idx = k\n",
    "                        break\n",
    "\n",
    "                up_embed = np.array(embedding_model.wv[idx_to_word[up_idx]])\n",
    "                below_embed = np.array(embedding_model.wv[idx_to_word[below_idx]])\n",
    "                mean_oov_word = np.mean((up_embed, below_embed), axis=0)\n",
    "                embedding_matrix[idx, :] = mean_oov_word\n",
    "    if consider_oov == False:\n",
    "        # delete all the cells that have all values zeros, this because these\n",
    "        # rows has not been initialized since we did not condier the oov terms\n",
    "        embedding_matrix =  embedding_matrix[np.all(embedding_matrix != 0, axis=1)]\n",
    "    return embedding_matrix\n",
    "\n",
    "# Testing\n",
    "embedding_matrix = build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, oov_terms)\n",
    "\n",
    "print(\"Embedding matrix shape: {}\".format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at an embedding of a word\n",
    "#embedding_matrix[word_tokenizer.word_index['home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2300, 46)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tags\n",
    "num_classes = y.shape[2]\n",
    "#vocabulary_size = len(word_tokenizer.word_index) + 1\n",
    "vocabulary_size = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  embedding_matrix.shape[0],         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  embedding_dimension,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 4.1239 - acc: 0.0052\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 3.8134 - acc: 0.0058\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 3.6521 - acc: 0.0059\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 3.5530 - acc: 0.0058\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 3.4469 - acc: 0.0058\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 3.3256 - acc: 0.0119\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 3.1969 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 3.0637 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 2.9289 - acc: 0.7911\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 2.7913 - acc: 0.7907\n"
     ]
    }
   ],
   "source": [
    "rnn_training = rnn_model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim     = vocabulary_size,         # vocabulary size - number of unique words in data\n",
    "                         output_dim    = embedding_dimension,          # length of vector with which each word is represented\n",
    "                         input_length  = MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                         weights       = [embedding_matrix],     # word embedding matrix\n",
    "                         trainable     = True                     # True - update embeddings_weight matrix\n",
    "))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss      =  'categorical_crossentropy',\n",
    "                   optimizer =  'adam',\n",
    "                   metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 3.8293 - acc: 0.7944\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.7977 - acc: 0.8040\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 3.7641 - acc: 0.8164\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 11s 105ms/step - loss: 3.7263 - acc: 0.8243\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 3.6819 - acc: 0.8290\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.6282 - acc: 0.8316\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 10s 105ms/step - loss: 3.5618 - acc: 0.8329\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 3.4779 - acc: 0.8336\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.3693 - acc: 0.8339\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 3.2251 - acc: 0.8340\n"
     ]
    }
   ],
   "source": [
    "lstm_training = lstm_model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "bidirect_model = Sequential()\n",
    "bidirect_model.add(Embedding(input_dim     = vocabulary_size,\n",
    "                             output_dim    = embedding_dimension,\n",
    "                             input_length  = MAX_SEQ_LENGTH,\n",
    "                             weights       = [embedding_matrix],\n",
    "                             trainable     = True\n",
    "))\n",
    "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "bidirect_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 4.0127 - acc: 0.0029\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 3.5543 - acc: 0.0029\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 3.1371 - acc: 0.7932\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 2.7586 - acc: 0.7929\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 2.4160 - acc: 0.7922\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 2.1093 - acc: 0.7916\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 1.8408 - acc: 0.7912\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.6122 - acc: 0.7910\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.4231 - acc: 0.7909\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 19s 190ms/step - loss: 1.2708 - acc: 0.7908\n"
     ]
    }
   ],
   "source": [
    "bidirect_training = bidirect_model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras' to_categorical function to one-hot encode Y\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, y_train = X[:100, :], y[:100, :, :]\n",
    "X_val, y_val = X[100:150, :], y[100:150, :, :]\n",
    "X_test, y_test = X[150:, :], y[150:, :, :]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
