{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4_wqPdlBcKS"
   },
   "source": [
    "# Assignment 3 : Sequence labelling with RNNs\n",
    "In this assignement we will ask you to perform POS tagging.\n",
    "\n",
    "You are asked to follow these steps:\n",
    "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
    "*   Embed the words using GloVe embeddings\n",
    "*   Create a baseline model, using a simple neural architecture\n",
    "*   Experiment doing small modifications to the model\n",
    "*   Evaluate your best model\n",
    "*   Analyze the errors of your model\n",
    "\n",
    "**Corpora**:\n",
    "Ignore the numeric value in the third column, use only the words/symbols and its label.\n",
    "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip \n",
    "\n",
    "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
    "\n",
    "**Baseline**: two layers architecture: a Bidirectional LSTM and a Dense/Fully-Connected layer on top.\n",
    "\n",
    "**Modifications**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and using a CRF in addition to the LSTM. Each of this change must be done by itself (don't mix these modifications).\n",
    "\n",
    "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
    "\n",
    "**Evaluation**: in the end, only the best model of your choice must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech (without considering punctuation classes).\n",
    "\n",
    "**Error Analysis** (optional) : analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
    "\n",
    "**Report**: You are asked to deliver a small report of about 4-5 lines in the .txt file that sums up your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%autosave 1\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all senteces\n",
    "data = []\n",
    "base_dir = 'dependency_treebank/'\n",
    "for filename in os.listdir(base_dir):\n",
    "    with open(base_dir + 'wsj_0001.dp') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [re.sub('\\s+', ' ', x) for x in content]\n",
    "    # remove empty strings\n",
    "    content = [x for x in content if x]\n",
    "    data.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitted sentences\n",
    "data = []\n",
    "base_dir = 'dependency_treebank/'\n",
    "for filename in os.listdir(base_dir):\n",
    "    with open(base_dir + 'wsj_0001.dp') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [re.sub('\\s+', ' ', x) for x in content]\n",
    "    sentences = []\n",
    "    sent_acc = []\n",
    "    for s in content:\n",
    "        if s != '':\n",
    "            sent_acc.append(s)\n",
    "        else:\n",
    "            sentences.append(sent_acc)\n",
    "            sent_acc = []\n",
    "    sentences.append(sent_acc)\n",
    "    data.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_labels(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for document in data:\n",
    "        X_i = []\n",
    "        y_i = []\n",
    "        for i in document:\n",
    "            X_i.append(i.split(' ')[0])\n",
    "            y_i.append(i.split(' ')[1])\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-9c439a1b0a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-952ff140bc28>\u001b[0m in \u001b[0;36msplit_features_labels\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mX_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "X, y = split_features_labels(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'PRP$',\n",
       " '$',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X)\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(y)\n",
    "y_encoded = tag_tokenizer.texts_to_sequences(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['First', 'Chicago', 'Corp.', 'said', 'it', 'completed', 'its', '$', '55.1', 'million', 'cash-and-stock', 'acquisition', 'of', 'closely', 'held', 'Ravenswood', 'Financial', 'Corp.', ',', 'another', 'Chicago', 'bank', 'holding', 'company', '.'] \n",
      "\n",
      "Y:  ['NNP', 'NNP', 'NNP', 'VBD', 'PRP', 'VBD', 'PRP$', '$', 'CD', 'CD', 'JJ', 'NN', 'IN', 'RB', 'VBN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NN', 'VBG', 'NN', '.'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [102, 156, 94, 15, 16, 1003, 36, 17, 3539, 35, 3540, 1004, 5, 1005, 403, 3541, 192, 94, 2, 196, 156, 146, 522, 42, 3] \n",
      "\n",
      "Y:  [3, 3, 3, 10, 17, 10, 22, 25, 9, 9, 6, 1, 2, 12, 16, 3, 3, 3, 7, 4, 3, 1, 18, 1, 8] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', y_encoded[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 4534\n"
     ]
    }
   ],
   "source": [
    "# check length of longest sentence\n",
    "lengths = [len(seq) for seq in X_encoded]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 2300  # sequences greater than 2300 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "y_padded = pad_sequences(y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ... 522  42   3] \n",
      "\n",
      "\n",
      "\n",
      "[ 0  0  0 ... 18  1  8]\n"
     ]
    }
   ],
   "source": [
    "print(X_padded[0], \"\\n\"*3)\n",
    "print(y_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_padded, y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2300), (100, 2300))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gloader\n",
    "\n",
    "def load_embedding_model(model_type, embedding_dimension=50):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained word embedding model via gensim library.\n",
    "\n",
    "    :param model_type: name of the word embedding model to load.\n",
    "    :param embedding_dimension: size of the embedding space to consider\n",
    "\n",
    "    :return\n",
    "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
    "    \"\"\"\n",
    "\n",
    "    download_path = \"\"\n",
    "    '''\n",
    "    # Find the correct embedding model name\n",
    "    if model_type.strip().lower() == 'word2vec':\n",
    "        download_path = \"word2vec-google-news-300\"\n",
    "    '''\n",
    "    if model_type.strip().lower() == 'glove':\n",
    "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "\n",
    "    else:\n",
    "        raise AttributeError(\"Unsupported embedding model type! Available ones: word2vec, glove\")\n",
    "\n",
    "    # Check download\n",
    "    try:\n",
    "        emb_model = gloader.load(download_path)\n",
    "    except ValueError as e:\n",
    "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "        print(\"Word2Vec: 300\")\n",
    "        print(\"Glove: 50, 100, 200, 300\")\n",
    "        raise e\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_type = \"glove\"\n",
    "embedding_dimension = 50\n",
    "embedding_model = load_embedding_model(embedding_model_type, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523603677749634),\n",
       " ('throne', 0.7664334177970886),\n",
       " ('prince', 0.759214460849762),\n",
       " ('daughter', 0.7473883032798767),\n",
       " ('elizabeth', 0.7460220456123352),\n",
       " ('princess', 0.7424569725990295),\n",
       " ('kingdom', 0.7337411642074585),\n",
       " ('monarch', 0.7214490175247192),\n",
       " ('eldest', 0.7184861898422241),\n",
       " ('widow', 0.7099430561065674)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.most_similar(positive = [\"king\", \"woman\"], negative = [\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(df):\n",
    "    X, y = split_features_labels(df)\n",
    "    flat_list = [item for sublist in X for item in sublist]\n",
    "    vocab = set(flat_list)\n",
    "    vocab_dict = {} # word to index\n",
    "    current_index = 0\n",
    "    for v in vocab:\n",
    "        vocab_dict[v] = current_index\n",
    "        current_index += 1\n",
    "    \n",
    "    voc_index_to_word = {v: k for k, v in vocab_dict.items()}\n",
    "    \n",
    "    return voc_index_to_word, vocab_dict, np.array(list(vocab_dict.keys()))\n",
    " \n",
    "\n",
    "\n",
    "# Testing\n",
    "idx_to_word, word_to_idx, word_listing = build_vocabulary(data[:100]) # only training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_OOV_terms(embedding_model, word_listing):\n",
    "    \"\"\"\n",
    "    Checks differences between pre-trained embedding model vocabulary\n",
    "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
    "\n",
    "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
    "    :param word_listing: dataset specific vocabulary (list)\n",
    "\n",
    "    :return\n",
    "        - list of OOV terms\n",
    "    \"\"\"\n",
    "    \n",
    "    model_vocab_array = np.array(list(embedding_model.vocab.keys()))\n",
    "    return list(np.setdiff1d(word_listing, model_vocab_array))\n",
    "\n",
    "oov_terms = check_OOV_terms(embedding_model, word_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV terms: 2258 (0.28%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total OOV terms: {0} ({1:.2f}%)\".format(len(oov_terms), float(len(oov_terms)) / len(word_listing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (8068, 50)\n"
     ]
    }
   ],
   "source": [
    "def build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, oov_terms, consider_oov=True):\n",
    "    \"\"\"\n",
    "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
    "\n",
    "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
    "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
    "    :param oov_terms: list of OOV terms (list)\n",
    "    :param co_occorruence_count_matrix: the co-occurrence count matrix of the given dataset (window size 1)\n",
    "\n",
    "    :return\n",
    "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
    "    \"\"\"\n",
    "    words = np.array(list(word_to_idx.keys()))\n",
    "    embedding_matrix = np.zeros((len(words), embedding_dimension))    \n",
    "    for idx, w in enumerate(words):\n",
    "        if w not in oov_terms:\n",
    "            embedding_matrix[idx, :] = np.array(embedding_model.wv[w])\n",
    "        elif consider_oov == True and idx < len(words) and idx > 0:\n",
    "                # get the first 2 word in the vocab close to the current word index\n",
    "                below_idx = -1\n",
    "                up_idx = -1\n",
    "                model_vocab = list(embedding_model.vocab.keys())\n",
    "\n",
    "                for i in range(idx + 1, len(words)):\n",
    "                    if idx_to_word[i] in model_vocab:\n",
    "                        below_idx = i\n",
    "                        up_idx = i\n",
    "                        break\n",
    "\n",
    "                for k in reversed(range(0, idx - 1)):\n",
    "                    if idx_to_word[k] in model_vocab:\n",
    "                        up_idx = k\n",
    "                        below_idx = k\n",
    "                        break\n",
    "\n",
    "                up_embed = np.array(embedding_model.wv[idx_to_word[up_idx]])\n",
    "                below_embed = np.array(embedding_model.wv[idx_to_word[below_idx]])\n",
    "                mean_oov_word = np.mean((up_embed, below_embed), axis=0)\n",
    "                embedding_matrix[idx, :] = mean_oov_word\n",
    "    if consider_oov == False:\n",
    "        # delete all the cells that have all values zeros, this because these\n",
    "        # rows has not been initialized since we did not condier the oov terms\n",
    "        embedding_matrix =  embedding_matrix[np.all(embedding_matrix != 0, axis=1)]\n",
    "    return embedding_matrix\n",
    "\n",
    "# Testing\n",
    "embedding_matrix = build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, oov_terms)\n",
    "\n",
    "print(\"Embedding matrix shape: {}\".format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at an embedding of a word\n",
    "#embedding_matrix[word_tokenizer.word_index['home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2300, 46)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tags\n",
    "num_classes = y.shape[2]\n",
    "#vocabulary_size = len(word_tokenizer.word_index) + 1\n",
    "vocabulary_size = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  embedding_matrix.shape[0],         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  embedding_dimension,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 4.1239 - acc: 0.0052\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 3.8134 - acc: 0.0058\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 3.6521 - acc: 0.0059\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 3.5530 - acc: 0.0058\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 3.4469 - acc: 0.0058\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 3.3256 - acc: 0.0119\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 3.1969 - acc: 0.7962\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 3.0637 - acc: 0.7944\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 2.9289 - acc: 0.7911\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 2.7913 - acc: 0.7907\n"
     ]
    }
   ],
   "source": [
    "rnn_training = rnn_model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim     = vocabulary_size,         # vocabulary size - number of unique words in data\n",
    "                         output_dim    = embedding_dimension,          # length of vector with which each word is represented\n",
    "                         input_length  = MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                         weights       = [embedding_matrix],     # word embedding matrix\n",
    "                         trainable     = True                     # True - update embeddings_weight matrix\n",
    "))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss      =  'categorical_crossentropy',\n",
    "                   optimizer =  'adam',\n",
    "                   metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pptr/.conda/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 3.8293 - acc: 0.7944\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.7977 - acc: 0.8040\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 3.7641 - acc: 0.8164\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 11s 105ms/step - loss: 3.7263 - acc: 0.8243\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 3.6819 - acc: 0.8290\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.6282 - acc: 0.8316\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 10s 105ms/step - loss: 3.5618 - acc: 0.8329\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 3.4779 - acc: 0.8336\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.3693 - acc: 0.8339\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 3.2251 - acc: 0.8340\n"
     ]
    }
   ],
   "source": [
    "lstm_training = lstm_model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "bidirect_model = Sequential()\n",
    "bidirect_model.add(Embedding(input_dim     = vocabulary_size,\n",
    "                             output_dim    = embedding_dimension,\n",
    "                             input_length  = MAX_SEQ_LENGTH,\n",
    "                             weights       = [embedding_matrix],\n",
    "                             trainable     = True\n",
    "))\n",
    "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "bidirect_model.add(TimeDistributed(Dense(num_classes, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 1.1513 - acc: 0.7908\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.0594 - acc: 0.7907\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.9899 - acc: 0.7907\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.9379 - acc: 0.7907\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8991 - acc: 0.7907\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.8700 - acc: 0.7907\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8479 - acc: 0.7908\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8308 - acc: 0.7908\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.8170 - acc: 0.7908\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.8054 - acc: 0.7908\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7954 - acc: 0.7909\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7864 - acc: 0.7910\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.7781 - acc: 0.7913\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7704 - acc: 0.7916\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.7633 - acc: 0.7923\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7567 - acc: 0.7934\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.7505 - acc: 0.7952\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7448 - acc: 0.7976\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7395 - acc: 0.8006\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7344 - acc: 0.8038\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7296 - acc: 0.8073\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.7249 - acc: 0.8105\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7204 - acc: 0.8130\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.7159 - acc: 0.8152\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.7115 - acc: 0.8170\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7070 - acc: 0.8182\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7026 - acc: 0.8192\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6982 - acc: 0.8198\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6938 - acc: 0.8203\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6895 - acc: 0.8207\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6852 - acc: 0.8208\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6811 - acc: 0.8209\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.6771 - acc: 0.8210\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6732 - acc: 0.8211\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.6695 - acc: 0.8212\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.6660 - acc: 0.8212\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6628 - acc: 0.8213\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6597 - acc: 0.8213\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6568 - acc: 0.8213\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6541 - acc: 0.8215\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6515 - acc: 0.8216\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.6490 - acc: 0.8219\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6467 - acc: 0.8222\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6444 - acc: 0.8227\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6421 - acc: 0.8233\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.6398 - acc: 0.8241\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6375 - acc: 0.8251\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6352 - acc: 0.8262\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6330 - acc: 0.8273\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6308 - acc: 0.8283\n"
     ]
    }
   ],
   "source": [
    "bidirect_training = bidirect_model.fit(X, y, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras' to_categorical function to one-hot encode Y\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, y_train = X[:100, :], y[:100, :, :]\n",
    "X_val, y_val = X[100:150, :], y[100:150, :, :]\n",
    "X_test, y_test = X[150:, :], y[150:, :, :]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
