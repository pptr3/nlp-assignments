{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import torchtext\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(base_dir, datafields):\n",
    "    examples = []\n",
    "    for filename in os.listdir(base_dir):\n",
    "        with open(base_dir + filename, encoding='utf-8') as f:\n",
    "            words = []\n",
    "            labels = []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line: # if is not empty string\n",
    "                    columns = line.split()\n",
    "                    words.append(columns[0]) # take the word\n",
    "                    labels.append(columns[-2]) # take the POS tag\n",
    "            examples.append(torchtext.data.Example.fromlist([words, labels], datafields))\n",
    "    return torchtext.data.Dataset(examples, datafields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True)\n",
    "LABEL = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, unk_token=None)        \n",
    "fields = [('text', TEXT), ('label', LABEL)]\n",
    "base_dir = '../dependency_treebank/'\n",
    "d = read_data(base_dir, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['First', 'Chicago', 'Corp.', 'said', 'it', 'completed', 'its', '$', '55.1', 'million', 'cash-and-stock', 'acquisition', 'of', 'closely', 'held', 'Ravenswood', 'Financial', 'Corp.', ',', 'another', 'Chicago', 'bank', 'holding', 'company', '.'], 'label': ['NNP', 'NNP', 'NNP', 'VBD', 'PRP', 'VBD', 'PRP$', '$', 'CD', 'CD', 'JJ', 'NN', 'IN', 'RB', 'VBN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NNP', 'NN', 'VBG', 'NN', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(d.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, text_field, label_field, emb_dim, rnn_size, update_pretrained=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        voc_size = len(text_field.vocab)\n",
    "        self.n_labels = len(label_field.vocab)       \n",
    "        \n",
    "        # Embedding layer. If we're using pre-trained embeddings, copy them\n",
    "        # into our embedding module.\n",
    "        self.embedding = nn.Embedding(voc_size, emb_dim)\n",
    "        if text_field.vocab.vectors is not None:\n",
    "            self.embedding.weight = torch.nn.Parameter(text_field.vocab.vectors, \n",
    "                                                       requires_grad=update_pretrained)\n",
    "\n",
    "        # RNN layer. We're using a bidirectional GRU with one layer.\n",
    "        self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=1)\n",
    "\n",
    "        # Output layer. As in the example last week, the input will be two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(2*rnn_size, self.n_labels)\n",
    "        \n",
    "        # To deal with the padding positions later, we need to know the\n",
    "        # encoding of the padding dummy word and the corresponding dummy output tag.\n",
    "        self.pad_word_id = text_field.vocab.stoi[text_field.pad_token]\n",
    "        self.pad_label_id = label_field.vocab.stoi[label_field.pad_token]\n",
    "    \n",
    "        # Loss function that we will use during training.\n",
    "        self.loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "        \n",
    "    def compute_outputs(self, sentences):\n",
    "        # The words in the documents are encoded as integers. The shape of the documents\n",
    "        # tensor is (max_len, n_docs), where n_docs is the number of documents in this batch,\n",
    "        # and max_len is the maximal length of a document in the batch.\n",
    "\n",
    "        # First look up the embeddings for all the words in the documents.\n",
    "        # The shape is now (max_len, n_sentences, emb_dim).        \n",
    "        embedded = self.embedding(sentences)\n",
    "\n",
    "        # Apply the RNN.\n",
    "        # The shape of the RNN output tensor is (max_len, n_sentences, 2*rnn_size).\n",
    "        rnn_out, _ = self.rnn(embedded)\n",
    "        \n",
    "        # Apply the linear output layer.\n",
    "        # The shape of the output tensor is (max_len, n_sentences, n_labels).\n",
    "        out = self.top_layer(rnn_out)\n",
    "        \n",
    "        # Find the positions where the token is a dummy padding token.\n",
    "        pad_mask = (sentences == self.pad_word_id).float()\n",
    "\n",
    "        # For these positions, we add some large number in the column corresponding\n",
    "        # to the dummy padding label.\n",
    "        out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "\n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels):\n",
    "        # As discussed above, this method first computes the predictions, and then\n",
    "        # the loss function.\n",
    "        \n",
    "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
    "        scores = self.compute_outputs(sentences)\n",
    "        \n",
    "        # Flatten the outputs and the gold-standard labels, to compute the loss.\n",
    "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
    "        scores = scores.view(-1, self.n_labels)\n",
    "        labels = labels.view(-1)\n",
    "        return self.loss(scores, labels)\n",
    "\n",
    "    def predict(self, sentences):\n",
    "        # Compute the outputs from the linear units.\n",
    "        scores = self.compute_outputs(sentences)\n",
    "\n",
    "        # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
    "        predicted = scores.argmax(dim=2)\n",
    "\n",
    "        # We transpose the prediction to (n_sentences, max_len), and convert it\n",
    "        # to a NumPy matrix.\n",
    "        return predicted.t().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNCRFTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, text_field, label_field, emb_dim, rnn_size, update_pretrained=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        voc_size = len(text_field.vocab)\n",
    "        self.n_labels = len(label_field.vocab)       \n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, emb_dim)\n",
    "        if text_field.vocab.vectors is not None:\n",
    "            self.embedding.weight = torch.nn.Parameter(text_field.vocab.vectors, \n",
    "                                                       requires_grad=update_pretrained)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=1)\n",
    "\n",
    "        self.top_layer = nn.Linear(2*rnn_size, self.n_labels)\n",
    "        \n",
    "        self.pad_word_id = text_field.vocab.stoi[text_field.pad_token]\n",
    "        self.pad_label_id = label_field.vocab.stoi[label_field.pad_token]\n",
    "    \n",
    "        self.crf = CRF(self.n_labels)\n",
    "        \n",
    "    def compute_outputs(self, sentences):\n",
    "        embedded = self.embedding(sentences)\n",
    "        rnn_out, _ = self.rnn(embedded)\n",
    "        out = self.top_layer(rnn_out)\n",
    "        \n",
    "        pad_mask = (sentences == self.pad_word_id).float()\n",
    "        out[:, :, self.pad_label_id] += pad_mask*10000\n",
    "        \n",
    "        return out\n",
    "                \n",
    "    def forward(self, sentences, labels):\n",
    "        # Compute the outputs of the lower layers, which will be used as emission\n",
    "        # scores for the CRF.\n",
    "        scores = self.compute_outputs(sentences)\n",
    "\n",
    "        # We return the loss value. The CRF returns the log likelihood, but we return \n",
    "        # the *negative* log likelihood as the loss value.            \n",
    "        # PyTorch's optimizers *minimize* the loss, while we want to *maximize* the\n",
    "        # log likelihood.\n",
    "        return -self.crf(scores, labels)\n",
    "            \n",
    "    def predict(self, sentences):\n",
    "        # Compute the emission scores, as above.\n",
    "        scores = self.compute_outputs(sentences)\n",
    "\n",
    "        # Apply the Viterbi algorithm to get the predictions. This implementation returns\n",
    "        # the result as a list of lists (not a tensor), corresponding to a matrix\n",
    "        # of shape (n_sentences, max_len).\n",
    "        return self.crf.decode(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a list of BIO labels, coded as integers, into spans identified by a beginning, an end, and a label.\n",
    "# To allow easy comparison later, we store them in a dictionary indexed by the start position.\n",
    "def to_spans(l_ids, voc):\n",
    "    spans = {}\n",
    "    current_lbl = None\n",
    "    current_start = None\n",
    "    for i, l_id in enumerate(l_ids):\n",
    "        l = voc[l_id]\n",
    "\n",
    "        if l[0] == 'B': \n",
    "            # Beginning of a named entity: B-something.\n",
    "            if current_lbl:\n",
    "                # If we're working on an entity, close it.\n",
    "                spans[current_start] = (current_lbl, i)\n",
    "            # Create a new entity that starts here.\n",
    "            current_lbl = l[2:]\n",
    "            current_start = i\n",
    "        elif l[0] == 'I':\n",
    "            # Continuation of an entity: I-something.\n",
    "            if current_lbl:\n",
    "                # If we have an open entity, but its label does not\n",
    "                # correspond to the predicted I-tag, then we close\n",
    "                # the open entity and create a new one.\n",
    "                if current_lbl != l[2:]:\n",
    "                    spans[current_start] = (current_lbl, i)\n",
    "                    current_lbl = l[2:]\n",
    "                    current_start = i\n",
    "            else:\n",
    "                # If we don't have an open entity but predict an I tag,\n",
    "                # we create a new entity starting here even though we're\n",
    "                # not following the format strictly.\n",
    "                current_lbl = l[2:]\n",
    "                current_start = i\n",
    "        else:\n",
    "            # Outside: O.\n",
    "            if current_lbl:\n",
    "                # If we have an open entity, we close it.\n",
    "                spans[current_start] = (current_lbl, i)\n",
    "                current_lbl = None\n",
    "                current_start = None\n",
    "    return spans\n",
    "\n",
    "# Compares two sets of spans and records the results for future aggregation.\n",
    "def compare(gold, pred, stats):\n",
    "    for start, (lbl, end) in gold.items():\n",
    "        stats['total']['gold'] += 1\n",
    "        stats[lbl]['gold'] += 1\n",
    "    for start, (lbl, end) in pred.items():\n",
    "        stats['total']['pred'] += 1\n",
    "        stats[lbl]['pred'] += 1\n",
    "    for start, (glbl, gend) in gold.items():\n",
    "        if start in pred:\n",
    "            plbl, pend = pred[start]\n",
    "            if glbl == plbl and gend == pend:\n",
    "                stats['total']['corr'] += 1\n",
    "                stats[glbl]['corr'] += 1\n",
    "\n",
    "# This function combines the auxiliary functions we defined above.\n",
    "def evaluate_iob(predicted, gold, label_field, stats):\n",
    "    # The gold-standard labels are assumed to be an integer tensor of shape\n",
    "    # (max_len, n_sentences), as returned by torchtext.\n",
    "    gold_cpu = gold.t().cpu().numpy()\n",
    "    gold_cpu = list(gold_cpu.reshape(-1))\n",
    "\n",
    "    # The predicted labels assume the format produced by pytorch-crf, so we\n",
    "    # assume that they have been converted into a list already.\n",
    "    # We just flatten the list.\n",
    "    pred_cpu = [l for sen in predicted for l in sen]\n",
    "    \n",
    "    # Compute spans for the gold standard and prediction.\n",
    "    gold_spans = to_spans(gold_cpu, label_field.vocab.itos)\n",
    "    pred_spans = to_spans(pred_cpu, label_field.vocab.itos)\n",
    "\n",
    "    # Finally, update the counts for correct, predicted and gold-standard spans.\n",
    "    compare(gold_spans, pred_spans, stats)\n",
    "\n",
    "# Computes precision, recall and F-score, given a dictionary that contains\n",
    "# the counts of correct, predicted and gold-standard items.\n",
    "def prf(stats):\n",
    "    if stats['pred'] == 0:\n",
    "        return 0, 0, 0\n",
    "    p = stats['corr']/stats['pred']\n",
    "    r = stats['corr']/stats['gold']\n",
    "    if p > 0 and r > 0:\n",
    "        f = 2*p*r/(p+r)\n",
    "    else:\n",
    "        f = 0\n",
    "    return p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using pre-trained word embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2050624/2051328 [03:51<00:00, 8632.89it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Vector for token b'Sonezaki' has 217 dimensions, but previously read vectors have 300 dimensions. All vectors must have the same number of dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-84af38236adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-84af38236adc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'We are using pre-trained word embeddings.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glove.840B.300d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'We are training word embeddings from scratch.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[1;32m    308\u001b[0m             if tok is not None))\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    181\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    404\u001b[0m                             \u001b[0;34m\"read vectors have {} dimensions. All vectors must have \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                             \"the same number of dimensions.\".format(word, len(entries),\n\u001b[0;32m--> 406\u001b[0;31m                                                                     dim))\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Vector for token b'Sonezaki' has 217 dimensions, but previously read vectors have 300 dimensions. All vectors must have the same number of dimensions."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 2050624/2051328 [04:10<00:00, 8632.89it/s]"
     ]
    }
   ],
   "source": [
    "class Tagger:\n",
    "    \n",
    "    def __init__(self, lower):\n",
    "        self.TEXT = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, lower=lower)\n",
    "        self.LABEL = torchtext.data.Field(init_token='<bos>', eos_token='<eos>', sequential=True, unk_token=None)\n",
    "        self.fields = [('text', self.TEXT), ('label', self.LABEL)]\n",
    "        self.device = 'cuda'\n",
    "        \n",
    "    def tag(self, sentences):\n",
    "        # This method applies the trained model to a list of sentences.\n",
    "        \n",
    "        # First, create a torchtext Dataset containing the sentences to tag.\n",
    "        examples = []\n",
    "        for sen in sentences:\n",
    "            labels = ['?']*len(sen) # placeholder\n",
    "            examples.append(torchtext.data.Example.fromlist([sen, labels], self.fields))\n",
    "        dataset = torchtext.data.Dataset(examples, self.fields)\n",
    "        \n",
    "        iterator = torchtext.data.Iterator(\n",
    "            dataset,\n",
    "            device=self.device,\n",
    "            batch_size=64,\n",
    "            repeat=False,\n",
    "            train=False,\n",
    "            sort=False)\n",
    "        \n",
    "        # Apply the trained model to all batches.\n",
    "        out = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterator:\n",
    "                # Call the model's predict method. This returns a list of NumPy matrix\n",
    "                # containing the integer-encoded tags for each sentence.\n",
    "                predicted = self.model.predict(batch.text)\n",
    "\n",
    "                # Convert the integer-encoded tags to tag strings.\n",
    "                for tokens, pred_sen in zip(sentences, predicted):\n",
    "                    out.append([self.LABEL.vocab.itos[pred_id] for _, pred_id in zip(tokens, pred_sen[1:])])\n",
    "        return out\n",
    "                \n",
    "    def train(self):\n",
    "        # Read training and validation data according to the predefined split.\n",
    "        base_dir = '../dependency_treebank/'\n",
    "        train_examples = read_data(base_dir, self.fields)\n",
    "        valid_examples = read_data(base_dir, self.fields)\n",
    "\n",
    "        # Count the number of words and sentences.\n",
    "        n_tokens_train = 0\n",
    "        n_sentences_train = 0\n",
    "        for ex in train_examples:\n",
    "            n_tokens_train += len(ex.text) + 2\n",
    "            n_sentences_train += 1\n",
    "        n_tokens_valid = 0       \n",
    "        for ex in valid_examples:\n",
    "            n_tokens_valid += len(ex.text)\n",
    "\n",
    "        # Load the pre-trained embeddings that come with the torchtext library.\n",
    "        use_pretrained = True\n",
    "        if use_pretrained:\n",
    "            print('We are using pre-trained word embeddings.')\n",
    "            self.TEXT.build_vocab(train_examples, vectors=\"glove.840B.300d\")\n",
    "        else:  \n",
    "            print('We are training word embeddings from scratch.')\n",
    "            self.TEXT.build_vocab(train_examples, max_size=5000)\n",
    "        self.LABEL.build_vocab(train_examples)\n",
    "    \n",
    "        # Create one of the models defined above.\n",
    "        #self.model = RNNTagger(self.TEXT, self.LABEL, emb_dim=300, rnn_size=128, update_pretrained=False)\n",
    "        self.model = RNNCRFTagger(self.TEXT, self.LABEL, emb_dim=300, rnn_size=128, update_pretrained=False)\n",
    "    \n",
    "        self.model.to(self.device)\n",
    "    \n",
    "        batch_size = 64\n",
    "        n_batches = np.ceil(n_sentences_train / batch_size)\n",
    "\n",
    "        mean_n_tokens = n_tokens_train / n_batches\n",
    "\n",
    "        train_iterator = torchtext.data.BucketIterator(\n",
    "            train_examples,\n",
    "            device=self.device,\n",
    "            batch_size=batch_size,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            repeat=False,\n",
    "            train=True,\n",
    "            sort=True)\n",
    "\n",
    "        valid_iterator = torchtext.data.BucketIterator(\n",
    "            valid_examples,\n",
    "            device=self.device,\n",
    "            batch_size=64,\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            repeat=False,\n",
    "            train=False,\n",
    "            sort=True)\n",
    "    \n",
    "        train_batches = list(train_iterator)\n",
    "        valid_batches = list(valid_iterator)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "        n_labels = len(self.LABEL.vocab)\n",
    "\n",
    "        history = defaultdict(list)    \n",
    "        \n",
    "        n_epochs = 1\n",
    "        \n",
    "        for i in range(1, n_epochs + 1):\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            loss_sum = 0\n",
    "\n",
    "            self.model.train()\n",
    "            for batch in train_batches:\n",
    "                \n",
    "                # Compute the output and loss.\n",
    "                loss = self.model(batch.text, batch.label) / mean_n_tokens\n",
    "                \n",
    "                optimizer.zero_grad()            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item()\n",
    "\n",
    "            train_loss = loss_sum / n_batches\n",
    "            history['train_loss'].append(train_loss)\n",
    "\n",
    "            # Evaluate on the validation set.\n",
    "            if i % 1 == 0:\n",
    "                stats = defaultdict(Counter)\n",
    "\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch in valid_batches:\n",
    "                        # Predict the model's output on a batch.\n",
    "                        predicted = self.model.predict(batch.text)                   \n",
    "                        # Update the evaluation statistics.\n",
    "                        evaluate_iob(predicted, batch.label, self.LABEL, stats)\n",
    "            \n",
    "                # Compute the overall F-score for the validation set.\n",
    "                _, _, val_f1 = prf(stats['total'])\n",
    "                \n",
    "                history['val_f1'].append(val_f1)\n",
    "            \n",
    "                t1 = time.time()\n",
    "                print(f'Epoch {i}: train loss = {train_loss:.4f}, val f1: {val_f1:.4f}, time = {t1-t0:.4f}')\n",
    "        \n",
    "        # After the final evaluation, we print more detailed evaluation statistics, including\n",
    "        # precision, recall, and F-scores for the different types of named entities.\n",
    "        print()\n",
    "        print('Final evaluation on the validation set:')\n",
    "        p, r, f1 = prf(stats['total'])\n",
    "        print(f'Overall: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        for label in stats:\n",
    "            if label != 'total':\n",
    "                p, r, f1 = prf(stats[label])\n",
    "                print(f'{label:4s}: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        \n",
    "        plt.plot(history['train_loss'])\n",
    "        plt.plot(history['val_f1'])\n",
    "        plt.legend(['training loss', 'validation F-score'])\n",
    "\n",
    "tagger = Tagger(lower=False)\n",
    "tagger.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
