{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 : Sequence labelling with RNNs\n",
    "In this assignement we will ask you to perform POS tagging.\n",
    "\n",
    "You are asked to follow these steps:\n",
    "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
    "*   Embed the words using GloVe embeddings\n",
    "*   Create a baseline model, using a simple neural architecture\n",
    "*   Experiment doing small modifications to the model\n",
    "*   Evaluate your best model\n",
    "*   Analyze the errors of your model\n",
    "\n",
    "**Corpora**:\n",
    "Ignore the numeric value in the third column, use only the words/symbols and its label.\n",
    "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip \n",
    "\n",
    "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
    "\n",
    "**Baseline**: two layers architecture: a Bidirectional LSTM and a Dense/Fully-Connected layer on top.\n",
    "**Modifications**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and using a CRF in addition to the LSTM. Each of this change must be done by itself (don't mix these modifications).<br>\n",
    "1) BiLSTM +  FC <br>\n",
    "2) BiGRU + FC <br>\n",
    "3) BiLSTMx2 + FC <br>\n",
    "4) BiLSTM +  FC + CRF <br>\n",
    "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
    "\n",
    "**Evaluation**: in the end, only the best model of your choice must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech (without considering punctuation classes).\n",
    "\n",
    "**Error Analysis** (optional) : analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
    "\n",
    "**Report**: You are asked to deliver a small report of about 4-5 lines in the .txt file that sums up your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(base_dir, datafields):\n",
    "    train = []\n",
    "    val = []\n",
    "    test = []\n",
    "    for filename in sorted(os.listdir(base_dir)):\n",
    "        if str(filename) < 'wsj_0100.dp': # get train data\n",
    "            with open(base_dir + filename, encoding='utf-8') as f:\n",
    "                words = []\n",
    "                labels = []\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line: # if is not empty string\n",
    "                        columns = line.split()\n",
    "                        words.append(columns[0]) # take the word\n",
    "                        labels.append(columns[-2]) # take the POS tag\n",
    "                train.append(torchtext.data.Example.fromlist([words, labels], datafields))\n",
    "        elif str(filename) < 'wsj_0150.dp':\n",
    "            with open(base_dir + filename, encoding='utf-8') as f:\n",
    "                words = []\n",
    "                labels = []\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line: # if is not empty string\n",
    "                        columns = line.split()\n",
    "                        words.append(columns[0]) # take the word\n",
    "                        labels.append(columns[-2]) # take the POS tag\n",
    "                val.append(torchtext.data.Example.fromlist([words, labels], datafields))\n",
    "        else:\n",
    "            with open(base_dir + filename, encoding='utf-8') as f:\n",
    "                words = []\n",
    "                labels = []\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line: # if is not empty string\n",
    "                        columns = line.split()\n",
    "                        words.append(columns[0]) # take the word\n",
    "                        labels.append(columns[-2]) # take the POS tag\n",
    "                test.append(torchtext.data.Example.fromlist([words, labels], datafields))\n",
    "    return torchtext.data.Dataset(train, datafields), torchtext.data.Dataset(val, datafields), torchtext.data.Dataset(test, datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.Field(lower = True)\n",
    "label = data.Field(unk_token = None)\n",
    "fields = [('text', text), ('label', label)]\n",
    "base_dir = '../dependency_treebank/'\n",
    "train_data, val_data, test_data = read_data(base_dir, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "text.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "label.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_percentage(tag_counts):\n",
    "    \n",
    "    total_count = sum([count for tag, count in tag_counts])\n",
    "    \n",
    "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
    "        \n",
    "    return tag_counts_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag\t\tCount\t\tPercentage\n",
      "\n",
      "NN\t\t6131\t\t13.2%\n",
      "NNP\t\t5104\t\t11.0%\n",
      "IN\t\t4852\t\t10.4%\n",
      "DT\t\t3990\t\t 8.6%\n",
      "NNS\t\t2966\t\t 6.4%\n",
      "JJ\t\t2948\t\t 6.3%\n",
      ",\t\t2526\t\t 5.4%\n",
      ".\t\t1917\t\t 4.1%\n",
      "VBD\t\t1518\t\t 3.3%\n",
      "RB\t\t1463\t\t 3.1%\n",
      "CD\t\t1414\t\t 3.0%\n",
      "VB\t\t1178\t\t 2.5%\n",
      "CC\t\t1124\t\t 2.4%\n",
      "VBZ\t\t1097\t\t 2.4%\n",
      "TO\t\t1015\t\t 2.2%\n",
      "VBN\t\t1012\t\t 2.2%\n",
      "PRP\t\t929\t\t 2.0%\n",
      "VBG\t\t740\t\t 1.6%\n",
      "VBP\t\t717\t\t 1.5%\n",
      "MD\t\t405\t\t 0.9%\n",
      "PRP$\t\t404\t\t 0.9%\n",
      "``\t\t402\t\t 0.9%\n",
      "POS\t\t398\t\t 0.9%\n",
      "''\t\t393\t\t 0.8%\n",
      "$\t\t336\t\t 0.7%\n",
      ":\t\t285\t\t 0.6%\n",
      "WDT\t\t199\t\t 0.4%\n",
      "JJR\t\t155\t\t 0.3%\n",
      "WP\t\t135\t\t 0.3%\n",
      "RP\t\t134\t\t 0.3%\n",
      "NNPS\t\t94\t\t 0.2%\n",
      "WRB\t\t91\t\t 0.2%\n",
      "JJS\t\t90\t\t 0.2%\n",
      "RBR\t\t85\t\t 0.2%\n",
      "-RRB-\t\t55\t\t 0.1%\n",
      "-LRB-\t\t52\t\t 0.1%\n",
      "EX\t\t48\t\t 0.1%\n",
      "RBS\t\t19\t\t 0.0%\n",
      "LS\t\t10\t\t 0.0%\n",
      "PDT\t\t9\t\t 0.0%\n",
      "WP$\t\t6\t\t 0.0%\n",
      "FW\t\t2\t\t 0.0%\n",
      "UH\t\t1\t\t 0.0%\n",
      "SYM\t\t1\t\t 0.0%\n",
      "#\t\t1\t\t 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(label.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch=False,\n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: a Bidirectional LSTM and a Dense/Fully-Connected layer on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 bidirectional,\n",
    "                 dropout,\n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, \n",
    "                          bidirectional=bidirectional, num_layers=1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.gru(embedded)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = BiLSTM(INPUT_DIM, \\n                        EMBEDDING_DIM, \\n                        HIDDEN_DIM, \\n                        OUTPUT_DIM, \\n                        N_LAYERS, \\n                        BIDIRECTIONAL, \\n                        DROPOUT, \\n                        PAD_IDX)'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(text.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(label.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = text.vocab.stoi[text.pad_token]\n",
    "TAG_PAD_IDX = label.vocab.stoi[label.pad_token]\n",
    "'''\n",
    "model = BiLSTM(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(text.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(label.vocab)\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = text.vocab.stoi[text.pad_token]\n",
    "TAG_PAD_IDX = label.vocab.stoi[label.pad_token]\n",
    "model = BiGRU(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the weights from a simple Normal distribution. Again, there may be a better initialization scheme for this model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGRU(\n",
       "  (embedding): Embedding(3389, 100, padding_idx=1)\n",
       "  (gru): GRU(100, 128, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=46, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a small function to tell us how many parameters are in our model. Useful for comparing different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 188,462 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now initialize our model's embedding layer with the pre-trained embedding values we loaded earlier.\n",
    "\n",
    "This is done by getting them from the vocab's `.vectors` attribute and then performing a `.copy` to overwrite the embedding layer's current weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3389, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = text.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3035,  0.3161,  0.0810,  ..., -1.0294, -0.0831, -0.2248],\n",
       "        [ 0.1103, -0.0265, -1.6802,  ...,  0.3054,  0.3394, -0.4928],\n",
       "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "        ...,\n",
       "        [ 0.0638,  0.0505, -0.0947,  ...,  0.0947, -0.3449,  0.0679],\n",
       "        [ 0.3079, -0.6757,  0.2158,  ...,  0.3156,  0.5600,  0.4885],\n",
       "        [-0.3110, -0.3398,  1.0308,  ...,  0.5317,  0.2836, -0.0640]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common to initialize the embedding of the pad token to all zeros. This, along with setting the `padding_idx` in the model's embedding layer, means that the embedding should always output a tensor full of zeros when a pad token is input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3035,  0.3161,  0.0810,  ..., -1.0294, -0.0831, -0.2248],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
      "        ...,\n",
      "        [ 0.0638,  0.0505, -0.0947,  ...,  0.0947, -0.3449,  0.0679],\n",
      "        [ 0.3079, -0.6757,  0.2158,  ...,  0.3156,  0.5600,  0.4885],\n",
      "        [-0.3110, -0.3398,  1.0308,  ...,  0.5317,  0.2836, -0.0640]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define our optimizer, used to update our parameters w.r.t. their gradients. We use Adam with the default learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our loss function, cross-entropy loss.\n",
    "\n",
    "Even though we have no `<unk>` tokens within our tag vocab, we still have `<pad>` tokens. This is because all sentences within a batch need to be the same size. However, we don't want to calculate the loss when the target is a `<pad>` token as we aren't training our model to recognize padding tokens.\n",
    "\n",
    "We handle this by setting the `ignore_index` in our loss function to the index of the padding token in our tag vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = label.vocab.stoi[label.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then place our model and loss function on our GPU, if we have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the loss value between our predicted and actual tags to train the network, but ideally we'd like a more interpretable way to see how well our model is doing - accuracy.\n",
    "\n",
    "The issue is that we don't want to calculate accuracy over the `<pad>` tokens as we aren't interested in predicting them.\n",
    "\n",
    "The function below only calculates accuracy over non-padded tokens. `non_pad_elements` is a tensor containing the indices of the non-pad tokens within an input batch. We then compare the predictions of those elements with the labels to get a count of how many predictions were correct. We then divide this by the number of non-pad elements to get our accuracy value over the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the function that handles training our model.\n",
    "\n",
    "We first set the model to `train` mode to turn on dropout/batch-norm/etc. (if used). Then we iterate over our iterator, which returns a batch of examples. \n",
    "\n",
    "For each batch: \n",
    "- we zero the gradients over the parameters from the last gradient calculation\n",
    "- insert the batch of text into the model to get predictions\n",
    "- as PyTorch loss functions cannot handle 3-dimensional predictions we reshape our predictions\n",
    "- calculate the loss and accuracy between the predicted tags and actual tags\n",
    "- call `backward` to calculate the gradients of the parameters w.r.t. the loss\n",
    "- take an optimizer `step` to update the parameters\n",
    "- add to the running total of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.label\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text)\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate` function is similar to the `train` function, except with changes made so we don't update the model's parameters.\n",
    "\n",
    "`model.eval()` is used to put the model in evaluation mode, so dropout/batch-norm/etc. are turned off. \n",
    "\n",
    "The iteration loop is also wrapped in `torch.no_grad` to ensure we don't calculate any gradients. We also don't need to call `optimizer.zero_grad()` and `optimizer.step()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.label\n",
    "            \n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have a small function that tells us how long an epoch takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train our model!\n",
    "\n",
    "After each epoch we check if our model has achieved the best validation loss so far. If it has then we save the parameters of this model and we will use these \"best\" parameters to calculate performance over our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load our \"best\" parameters and evaluate performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "88% accuracy looks pretty good, but let's see our model tag some actual sentences.\n",
    "\n",
    "We define a `tag_sentence` function that will:\n",
    "- put the model into evaluation mode\n",
    "- tokenize the sentence with spaCy if it is not a list\n",
    "- lowercase the tokens if the `Field` did\n",
    "- numericalize the tokens using the vocabulary\n",
    "- find out which tokens are not in the vocabulary, i.e. are `<unk>` tokens\n",
    "- convert the numericalized tokens into a tensor and add a batch dimension\n",
    "- feed the tensor into the model\n",
    "- get the predictions over the sentence\n",
    "- convert the predictions into readable tags\n",
    "\n",
    "As well as returning the tokens and tags, it also returns which tokens were `<unk>` tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "    \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
    "    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "         \n",
    "    predictions = model(token_tensor)\n",
    "    \n",
    "    top_predictions = predictions.argmax(-1)\n",
    "    \n",
    "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get an already tokenized example from the training set and test our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rudolph', 'agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', ',', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '.']\n"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['label']\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use our `tag_sentence` function to get the tags. Notice how the tokens referring to subject of the sentence, the \"respected cleric\", are both `<unk>` tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agnew', 'conglomerate']\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       text, \n",
    "                                       label)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check how well it did. Surprisingly, it got every token correct, including the two that were unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "NNP\t\tNNP\t\t✔\t\trudolph\n",
      "NNP\t\tNNP\t\t✔\t\tagnew\n",
      ",\t\t,\t\t✔\t\t,\n",
      "CD\t\tCD\t\t✔\t\t55\n",
      "NNS\t\tNNS\t\t✔\t\tyears\n",
      "JJ\t\tJJ\t\t✔\t\told\n",
      "CC\t\tCC\t\t✔\t\tand\n",
      "JJ\t\tJJ\t\t✔\t\tformer\n",
      "NN\t\tNN\t\t✔\t\tchairman\n",
      "IN\t\tIN\t\t✔\t\tof\n",
      "NNP\t\tNNP\t\t✔\t\tconsolidated\n",
      "NNP\t\tNNP\t\t✔\t\tgold\n",
      "NNP\t\tNNP\t\t✔\t\tfields\n",
      "NNP\t\tNNP\t\t✔\t\tplc\n",
      ",\t\t,\t\t✔\t\t,\n",
      "VBD\t\tVBD\t\t✔\t\twas\n",
      "VBN\t\tVBN\t\t✔\t\tnamed\n",
      "DT\t\tDT\t\t✔\t\ta\n",
      "JJ\t\tJJ\t\t✔\t\tnonexecutive\n",
      "NN\t\tNN\t\t✔\t\tdirector\n",
      "IN\t\tIN\t\t✔\t\tof\n",
      "DT\t\tDT\t\t✔\t\tthis\n",
      "JJ\t\tJJ\t\t✔\t\tbritish\n",
      "NN\t\tJJ\t\t✘\t\tindustrial\n",
      "NN\t\tNN\t\t✔\t\tconglomerate\n",
      ".\t\t.\t\t✔\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
